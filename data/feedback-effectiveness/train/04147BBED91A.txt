Detecting Emotions

New software has been developed that improves accuracy in percieving the emotions of others. The use of this technology to read the emotional expressions of students in a classroom could be valuable, or it could be a waste of time, depending on how you look at it.

Technology has been upgraded throughout recent decades, and most recently, technology has taken a different approach. The software is the latest innovation from Prof. Thomas Huang, in collaboration with Prof. Nicu Sebe. Dr. Huang and his colleagues are experts at developing better ways for humans and computers to communicate, but is this really a better way to communicate? It comes down to the facts. The computer constructs a 3-D computer model of the face, and then associated each with characteristic movements of the facial muscles. Everyone has different ways of expressing emotions, and not everyone feels the same emotions. Thinking that a computer could possibly detect your emotions is a bit silly, to some, and valuable to others. So what makes it silly to some? You can probably tell how a friend is feeling by the look on their face, you can talk with them in person. Having physical contact is very important when it comes to emotions, using a computer to detect, sounds a bit far-fetched. Schools have teachers, and school counselors, so that students can talk express how they feel. Some people don't see why this feature could possibly be useful in a classroom.

There are many issues going on in the world, much worse than trying to figure our expressions. So, why aren't we using this tchnology, and these smart people to work on something more important? Imagine a computer that knows when you're happy or sad, what would you need it for? Human communication is very important, using a computer to detect how you feel is simply a waste of time, in some opinions. Making faces can reveal so much about the science of emotion. On the other hand, what could the Facial Action Coding System be useful for in classrooms? Students may be able to use this feature in physiciatry studies. Students may also use this feature in art classes to really capture what the artist was depicting in the work. For instance, this new software was able to create percentages of Mona Lisa's emotions. The latest innovation in computer software may be very useful for art classes, knowing how a person may be feeling in a painting may help students to depict the artists work, a bit better. As humans, we can tell how someone may be feeling by the look on their face, or the look in their eyes. Most of us would have trouble trying to describe what facial expressions convey being happy, besides a smile. The computer can make exact percentages on each emotion you may be feeling. However, a computer cannot feel, cannot have sympathy, and cannot understand many things about humans. Reaching the final conclusion is up to you. Is a computer being able to identify your emotions useful in classrooms, or not? 