Have you ever wanted to just kick back and relax while your car does all of the driving? Have you ever thought about how dangerous that could be? I believe that semi or fully autonomous cars are a danger to the world. The cars are not not truly autonomous, nobody can really tell where responsibility lies when the computer is in control, and the technology that powers the cars may fail.

No car on the road today is completely computer controlled. The cars we have today run off of a computer, until it hits conditions it can not handle, requireing the driver to take over. In 2013, BMW made a vehicle that could run the car on its own, but the driver still had to hold on to the wheel. Many other cars have become semi autonomous, but require the driver to take over when there are different conditions, such as roadwork or there is an accident. Some of these semi auatonomous cars alert the driver when they need to take over, either by an indicator, physical vibration, or simply by announcing that the driver needs to take over. What if the driver falls asleep and the car fails to wake the driver to take control of the car? How safe is the car then?

Another problem with the reliablitly of these cars is the technology inside of them. The Google car for example, has sensors on the left rear wheel, a rotating sensor on the roof, a camera on the rearvier mirror, four automotive radar sensors, a GPS reciever, and an inertial motion sensor. The car runs off of all of these sensors, and needs every single one of them to run properly. But what happens if one of these sensors reade untrue values because they have malfunctioned or got covered up by something. Technology can only go so far into our lives before we are putting human life at risk. All it takes is one failure, one moment where a sensor isn't working correctly , and a persons life could be over. The sensors also cost money. This would make many of these cars almost unbuyable to the general public because of the cost of parts and matenience.

With all of that said, who is responsible if the car is in an accident or it kills somebody? Does the manufactorer who made the car get blamed, or does the driver who purchased it take responsibility? I personally belive that these cars are an assumed risk and that if the car is in an accident, that both the driver and the manufacterer are to blame. I believe that the driver could have attempted to do something to change the cars path, but it is more so the manuacturers fault becasue their car failed to stay in its own lane and out of the way of other traffic. The blame also depends on who was inc ontrol at the time of the accident, if the driver had control of the car, it is his or her fault. But if the computer was running the car, then it is the manufacturers fault.

These cars are not truly on autopilot, the technology is not completely reliable, and who is to blame for an accident? These points are all good reasons as to why these cars are a hazard to human life and should not be on our roads. So before you get right behind the idea of an autonomous car, think "do i trust my life and others lives to a machine?"      