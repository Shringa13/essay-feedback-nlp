I think the technology to read the emotional expressions of students in a classroom is valuable. The Facial Action Coding System (FACS) can prove how a person is feeling due to having a 3-D computer model, an electronic code, and a facial software.

First, the FACS has a 3-D computer model to help it figure out a persons emotion. In the text it says, "all 44 major muscles in the model must move like a humans muscles." This evidence shows that a humans facial muscles shows how a person is feeling and each emotion has their own charateristics.

Second, the FACS also has an electronic code which helps the system understand better the emotion just kanda how us as humans can tell if our friend is upset or happy. For example in the text it says, "His new computer software stores similar anatomical information as electronic code." This evidence shows that the software has the same kind of thing that lets us humans know how our friend is feeling.

Lastly, the facial software helps FACS by using human features on the face understand the emotions. In the article it says, "muscles called orbicularis oculi palpabraeus makes crow's-feet around your eyes. But in a false smile, the mouth is stretched sideways using the zygomatic major and a different muscle, the risorius." This evidence shows that even a computer software can tell what you're feeling by your face features.

I think the FACS should be used to read the emotion expressions of students in a classroom. Having a 3-D computer model, an electonic code, and a facial software sure can all help Facial Action Coding System recongize a humans emotion.