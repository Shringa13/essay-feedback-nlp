I feel like I am for the value of this use of technology, because you can calculate other peoples facial emotions and your facial movements.

I feel like if you can calculate emotions on a persons face you could understand that person better and what there feeling.

You could do a 3-D model of the face and put in all of the muscles just like a human has on their face.

You could understand if their happy, suprised, or even sad. Your frontalis pars lateralis muscles ( above the eyes ) raises your eyebrows when your suprised or scared.

Your emotions could be all over the place.

You could have certian facial expressions.

For an example, you could have your fear look. You could've saw something that you're afraid of and have a fear look. The software could even identify mixed emotions. Each expression is compared against a neutral face.

I know that everyone has different facial features, but some people have the same facial expressions.

I personally think that we should all have different facial features because no one can be the same and no one is perfect.

This technology could observe how our face is formed in the future.

This new technologyis the same technology for making computer-animated faces more expressive for video games or surgery. " Most human communication is nonverbal, including emotional communication " that Dr. Huang had. Computured need to understand that, too " said Dr. Huang.

Your personal computer can't handle the complex of the algorithms used to decode Mona Lisa's smile.

You sometimes has to ask yourself

" Does your expression in the mirror suggest an emotion?" and " Can your lab partner recognize which one? " So I think that this technology is a good idea.        