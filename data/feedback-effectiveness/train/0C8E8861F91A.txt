I agree with the claim against the value of using this technology to read student's emotional expressions. First off, we perform these calcutions everyday, as we can tell if our friend is happy or sad by looking at their face most of the time. Also, video imagery tells us that the facial emotions for each emotion are universal. Another big reason is that we really don't know just how much computers can do, it can be where computers detect whether you're happy or sad.

Performing this calculation every day, we would have trouble describing each facial trait that conveys happy, worried, etc. However, we can also use human anatomy to help paint precisely enough to convey specific emotions. New computer software has anatomical information as electronic code. Video imagery which is the new emotion-recognition software which tracks these facial movements in a real face or in the painted face of Mona Lisa. The software can detect mixed emotions by weighing the different units. We really don't know how much the computer can do, it can detect if you're happy or sad, and make computer-animated faces.

In a whole, this is a lot to disagree with, since computers are taking over our world now so I believe this is a great idea. Reason being is that we have video imagery, the amazing and undiscovered knowledge of a computer, and our own brains because we calculate expressions on our own every day. These our all major factors that align with the fact that I believe technology should be able to read students' emotional expressions.