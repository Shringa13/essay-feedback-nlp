I am going to argue for the value of having the Facial Action Coding System in the computers. I think it would be great to have something like this. The process beings when the computer constructs a 3-D computer model of your face. They would go through all 44 of your major face muscles because in order for them to work they must move like human muscles. Dr. Paul Eckman the creator of FACS has classified 6 very important emotions then mixed them together with each with facial muscles.

Then for classrooms like to tell if the students is either bored or confused about what he or she is susposed to be doing like they said in the article. Dr. Huang also prdicted that if you are talking about how if you are happy/smiling they would pop-up an ad for you being happy but if you are sad/frowning they will pull up something totally different for the ad.

Nobodies computer can hadle the complex algortihms used to decode Mona Lisa's smile but they can come up with soemthing to decode different emotions. This coding system is very smart and can tell if you are doing a fake smile of some sort. If you use a fake smile the system will tell if you are because when you are the mouth is streched sideways using the zygomatic major wih some different muscles. To an expert they said "faces don't lie" these muscle clues are often sometimes used to spot if a celebrity or a politician is being truthful. So I have came to conclusion that this facial action coding system works on any and everyone to tell their true emotions.                